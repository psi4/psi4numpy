{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psi4\n",
    "from psi4 import *\n",
    "from psi4.core import *\n",
    "import numpy as np\n",
    "import os\n",
    "sys.path.append('os.getcwd()')\n",
    "from opt_helper import stre, bend, intcosMisc, linearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rational Function Optimization\n",
    "\n",
    "Rational Function Optimization (RFO) is the method of choice for minimizations. This tutorial will walk through the basic theory of RFO and show a sample calculation.  The method was introduced for geometry optimizations by A. Banerjee, N. Adams, J. Simons, and R. Shepard in _J. Phys. Chem._ 89, 52 (1985).\n",
    "\n",
    "In the Newton-Raphson method, the potential energy surface is approximated by the truncated Taylor expansion in internal coordinates $q$ and gradient $g$ (where vectors are interpreted as columns).\n",
    "\n",
    "$$ \\epsilon = E(q) - E_0 = g^T \\Delta q + \\frac{1}{2}(\\Delta q)^T \\mathbf{H} \\Delta q $$\n",
    "\n",
    "An extension is to express the potential via a [2/2] Pade approximation, where __S__ is the scaling matrix.  If __S__ were zero, then the harmonic approximation would be obtained.\n",
    "\n",
    "$$ \\epsilon = \\frac{g^T\\Delta q + \\frac{1}{2} (\\Delta q)^T \\textbf{H} \\Delta q}{1 + \\Delta q^T \\textbf{S} \\Delta q} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relative energy expression can be rewritten in the form of $N+1$ dimensional vectors, where $N$ is the number of coordinates.\n",
    "\n",
    "$$ \\epsilon = \\frac{ \\frac{1}{2}\\begin{pmatrix} \\Delta{q^T} & 1\\end{pmatrix}\\begin{pmatrix} {\\textbf H} & g \\\\ g^T & 0  \\end{pmatrix}\\begin{pmatrix}\\Delta{q} \\\\ 1\\end{pmatrix} }{ \\begin{pmatrix} \\Delta q^T & 1 \\end{pmatrix} \\begin{pmatrix} \\textbf S & 0  \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} \\Delta q \\\\ 1 \\end{pmatrix}}$$\n",
    "\n",
    "since the right-hand side is\n",
    "\\begin{align}\n",
    "  &= \\frac{ \\frac{1}{2}\\begin{pmatrix} \\Delta{q^T} & 1\\end{pmatrix} \\begin{pmatrix} \\textbf{H} \\Delta q  + g \\\\ g^T \\Delta q + 0 \\end{pmatrix}}{\\begin{pmatrix} \\Delta q^T & 1 \\end{pmatrix} \\begin{pmatrix} \\textbf S \\Delta q + 0 \\\\ 0 + 1 \\end{pmatrix}} \\\\\n",
    "  \\\\\n",
    " &= \\frac { \\frac{1}{2} \\Delta q^T \\textbf H \\Delta q + \\frac{1}{2} \\Delta q^T g + \\frac{1}{2} g^T \\Delta q} { \\Delta q^T\\textbf S \\Delta q + 1}\n",
    " \\\\\n",
    "\\end{align}\n",
    "which is equivalent to the expression above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the stationary point assumption that  \n",
    "$$\\frac{\\partial \\epsilon}{\\partial q } = 0 $$\n",
    "we can derive the expression for the step.\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\epsilon}{\\partial q} &= \\frac {g + \\mathbf{H} \\Delta q}{1 + \\Delta q^T \\textbf S \\Delta q} - \\frac{ g \\Delta q^T + \\frac{1}{2} \\Delta q^T \\textbf H \\Delta q}{ 1 + \\Delta q^T \\textbf S \\Delta q} \\Big( \\frac{ 2 \\textbf S \\Delta q}{1 + \\Delta q^T \\textbf S \\Delta q}\\Big) \\\\\n",
    "\\\\\n",
    "\\frac{\\partial \\epsilon}{\\partial q} &= \\frac {g + \\textbf{H}\\Delta q}{1 + \\Delta q^T \\textbf S \\Delta q} - \\epsilon \\Big( \\frac{ 2 \\textbf S \\Delta q}{1 + \\Delta q^T \\textbf S \\Delta q} \\Big) \\\\\n",
    "\\\\\n",
    "0 &= \\frac{ g + \\textbf{H} \\Delta q - 2 \\epsilon \\textbf S \\Delta q}{1 + \\Delta q^T \\textbf S \\Delta q}\\\\\n",
    "\\\\\n",
    "0 &=  g + \\textbf{H} \\Delta q - 2 \\epsilon \\textbf S \\Delta q \\\\\n",
    "\\\\\n",
    "g + H\\Delta q &= 2 \\epsilon \\textbf S \\Delta q = \\lambda \\textbf S \\Delta q\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\lambda$ is defined as $2\\epsilon$.  It can be shown that \n",
    "$$\\lambda = g^T \\Delta q$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which allows the stationarity condition to be written as follows.\n",
    "\n",
    "\\begin{align}\n",
    "\\begin{pmatrix} \\textbf H \\Delta q \\\\ g^T \\Delta q \\end{pmatrix} + \\begin{pmatrix} g \\\\ 0 \\end{pmatrix} &= \\begin{pmatrix} \\lambda \\textbf S \\Delta q \\\\ \\lambda \\end{pmatrix} \\\\\n",
    "\\textrm{or} \\\\\n",
    "\\begin{pmatrix} \\textbf H & g \\\\ g^T & 0 \\end{pmatrix} \\begin{pmatrix} \\Delta q \\\\ 1 \\end{pmatrix} &= \\lambda \\begin{pmatrix} {\\textbf{S} \\Delta q} \\\\ 1 \\end{pmatrix} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The matrix __S__ is usually taken to be the identify matrix.  The result is an eigenvalue equation with $\\lambda$ as the eigenvalue!\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} \\textbf H & g \\\\ g^T & 0 \\end{pmatrix}\n",
    "\\begin{pmatrix} \\Delta q \\\\ 1 \\end{pmatrix} = \\lambda \\begin{pmatrix} { \\Delta q} \\\\ 1 \\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $N+1$ dimensional matrix on the left is called the \"RFO matrix\".  We build it from our Hessian and our gradient in internal coordinates.  Then the eigenvectors and eigenvalues of this matrix are determined.  For minimum-energy searches, we usually choose the eigenvector with the lowest value of $\\lambda$.  This value is hopefully negative, and is 2 times the  energy change anticipated from the step.  This eigenvector is intermediate-normalized by scaling the last element to 1.  The rest of the vector is the desired RFO step, or displacement in internal coordinates.\n",
    "\n",
    "Occasionally, this eigenvector has a very small final element, and cannot be intermediate normalized.  This comes about, for example, when the step breaks molecular symmetry and the projected energy change may be zero.  Also, the algorithm is numerically problematic if the gradients are very small.\n",
    "\n",
    "In practice, RFO performs better than ordinary Newton-Raphson steps if the energy surface being explored is not very harmonic, or if the optimization is begun far from a minimum.  However, if the potential surface is nearly flat (e.g., methane dimer), then RFO like ordinary N-R, will perform poorly.\n",
    "\n",
    "## Demonstration\n",
    "Now we prepare a water molecule and show an RFO step computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mol = psi4.geometry(\"\"\"\n",
    "O\n",
    "H 1 0.9\n",
    "H 1 0.9 2 104\n",
    "\"\"\")\n",
    "# We'll use cc-pVDZ RHF.\n",
    "psi4.set_options({\"basis\": \"cc-pvdz\"})\n",
    "mol.update_geometry()\n",
    "\n",
    "# Generate the internal coordinates manually.\n",
    "intcos = [stre.STRE(0,1), stre.STRE(0,2), bend.BEND(1,0,2)]\n",
    "for intco in intcos: \n",
    "    print(intco) \n",
    "\n",
    "# Handy variables for later.\n",
    "Natom = mol.natom()\n",
    "Nintco = len(intcos)\n",
    "Z = [int(mol.Z(i)) for i in range(Natom)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we guess the Hessian and compute the gradient in internal coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute initial guess Hessian.\n",
    "xyz = np.array(mol.geometry())\n",
    "\n",
    "H = np.zeros((Nintco,Nintco), float)\n",
    "for i,intco in enumerate(intcos):\n",
    "    H[i,i] = intco.diagonalHessianGuess(xyz, Z, guessType=\"SCHLEGEL\")\n",
    "\n",
    "print(\"\\n Schlegel Guess Hessian for Water (in au)\")\n",
    "print(H)\n",
    "\n",
    "g_x = np.reshape( np.array( psi4.gradient('scf')), (3*Natom))\n",
    "g_q = -1 * intcosMisc.qForces(intcos, xyz, g_x)\n",
    "\n",
    "print(\"Gradient in internal coordinates (au)\")\n",
    "print(g_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the RFO matrix and diagonalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dim = Nintco + 1\n",
    "RFOmat = np.zeros( (dim, dim), float)\n",
    "RFOmat[0:-1,0:-1] = H\n",
    "RFOmat[-1,0:-1] = g_q\n",
    "RFOmat[0:-1,-1] = g_q\n",
    "print(\"RFO matrix\")\n",
    "print(RFOmat)\n",
    "\n",
    "evals, evects = linearAlgebra.symmMatEig(RFOmat)\n",
    "print(\"Eigenvalues\")\n",
    "print(evals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Happily, there is in this case only 1 direction with a negative predicted energy change.  We choose the corresponding eigenvector, and then intermediate normalize it.  That is our desired RFO step in internal coordinates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RFOdq = evects[0]\n",
    "print(\"RFO eigenvector\")\n",
    "print(RFOdq)\n",
    "RFOdq[:] = RFOdq / RFOdq[-1]\n",
    "print(\"RFO intermediate normalized eigenvector\")\n",
    "print(RFOdq)\n",
    "# Now drop the 1 at the end.\n",
    "print(\"RFO step in internal coordinates\")\n",
    "RFOdq = RFOdq[0:-1]\n",
    "print(RFOdq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the desired step in internal coordinates.  We can see that the bond lengths and the bond angle will all increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "The Partioned-RFO method is an extension of the RFO method, and may be used to seek non-minimum stationary points such as transition states.  In the P-RFO method, there are two RFO matrices.  One is used for maximization along 1 or more degrees of freedom while the second one is for minimization along the others.  For the P-RFO method to be effective the starting geometry must be reasonable, and the curvature of the surface in different directions must be correctly represented by the Hessian.  Thus, it is usually necessary to compute the Hessian for a transition-state optimization so that the algorithm begin maximizing in the right direction.\n",
    "\n",
    "An extended scheme to limit the RFO step size called the restricted-step for RS-RFO method may be found in E. Besalu and J.M. Bofill, _Theor. Chem. Acc._ __100__, 265 (1998).  This involves an interation over repeated RFO matrix diagonalizations and does not always converge.  However, if it fails one simply resorts to more simple step-size scaling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
